{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "video_dir = r'./video/'\n",
    "pic_dir = r'./picture/'\n",
    "image_path = Path(f\"{pic_dir}/frame.png\")\n",
    "# gray, binary\n",
    "image = cv2.imread(str(image_path))\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "def show_and_wait(image, *images):\n",
    "    cv2.imshow(\"image\", image)\n",
    "    if images:\n",
    "        for i, image in enumerate(images):\n",
    "            cv2.imshow(f\"image{i}\", image)\n",
    "    k = cv2.waitKey(0)\n",
    "    if k == ord('s'):\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순서대로 \n",
    "#### 1. Edge Detection (가장자리 탐지)\n",
    "#### 2. Morphological Operations (형태학적 연산)\n",
    "#### 3. Connected Component Analysis (연결 요소 분석)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge Detection\n",
    "\n",
    "edges = cv2.Canny(gray, 100, 200)\n",
    "show_and_wait(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphological Transformations\n",
    "\n",
    "# Define a structuring element\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "# Perform morphological operations\n",
    "erosion = cv2.erode(image, kernel, iterations = 1)\n",
    "dilation = cv2.dilate(image, kernel, iterations = 1)\n",
    "opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Display the results\n",
    "show_and_wait(image, erosion, dilation, opening, closing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connected Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tesseract 이용 OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리 (예시: 그레이스케일 변환과 이진화)\n",
    "edges = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "# 이미지에서 텍스트 추출\n",
    "text = pytesseract.image_to_string(edges, lang='eng')  # 언어를 적절하게 설정하세요.\n",
    "\n",
    "# 인식된 텍스트 출력\n",
    "print(text, len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가장 밝은 pixel만 남기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(image_path)\n",
    "pixel_data = image.load()\n",
    "\n",
    "for y in range(image.size[1]):\n",
    "    for x in range(image.size[0]):\n",
    "        r, g, b = pixel_data[x, y]\n",
    "        if r > 200 and g > 200 and b > 200:\n",
    "            pixel_data[x, y] = (0, 0, 0)\n",
    "\n",
    "image.save(f\"{pic_dir}/frame2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.astype(np.float32) / 255.0\n",
    "threshold = 0.8\n",
    "white_pixels = np.where(np.sum(image[:, :, :3], axis=2) / 3 > threshold)\n",
    "print(white_pixels.__len__(), white_pixels[0])\n",
    "image[white_pixels] = [0, 0, 0, 0]\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "cv2.imwrite(f\"{pic_dir}/frame.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hu Moments:  [1.42444313e-03 5.59433644e-07 9.49004515e-11 9.31733822e-11\n",
      " 8.69180452e-21 2.24956563e-14 1.10186490e-21] (7,)\n"
     ]
    }
   ],
   "source": [
    "# 이진화: Otsu's method를 사용\n",
    "_, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "# Hu Moments를 계산하여 이미지 특성 추출\n",
    "hu_moments = cv2.HuMoments(cv2.moments(binary)).flatten()\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Hu Moments: \", hu_moments, hu_moments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# findContours 함수로 윤곽선 검출\n",
    "contours = binary.copy()\n",
    "contours, hierachy = cv2.findContours(contours, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(image, contours, -1, (0, 255, 0), 2)\n",
    "cv2.imshow(\"contours\", image)\n",
    "cv2.waitKey(1000)\n",
    "# type(contours)\n",
    "# len(contours)\n",
    "# for i in contours:\n",
    "#     print(i.shape)\n",
    "# type(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
